{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein Structure to Graph Converter\n",
    "\n",
    "## Tool Description\n",
    "\n",
    "This notebook converts protein structures (PDB format) into residue-level graph representations for geometric deep learning applications.\n",
    "\n",
    "### Purpose\n",
    "- **Input:** Directory containing one or more PDB files\n",
    "- **Output:** Graph objects representing residue-level protein structure graphs\n",
    "- **Graph Construction:** Distance cutoff-based edges between Cα atoms\n",
    "\n",
    "### Graph Definition (Scientific Specification)\n",
    "\n",
    "**Nodes:** One node per residue with Cα atom present\n",
    "\n",
    "**Node Features:**\n",
    "- Amino acid one-hot encoding (20 standard amino acids)\n",
    "- Residue index (sequential position)\n",
    "- Chain ID (encoded as integer)\n",
    "- Cα xyz coordinates (3D spatial position)\n",
    "\n",
    "**Edges:**\n",
    "- Undirected edges when Cα-Cα distance ≤ cutoff threshold\n",
    "- Edge features: Euclidean distance (Å)\n",
    "- Bidirectional representation (both edge directions stored)\n",
    "\n",
    "### Two Graph Generation Modes\n",
    "\n",
    "**1. Monomer Mode:**\n",
    "- One graph per chain\n",
    "- Only intra-chain edges\n",
    "- Output: `protein_chainA.pt`\n",
    "\n",
    "**2. Complex Mode:**\n",
    "- One graph per structure (all chains combined)\n",
    "- Includes inter-chain edges if within cutoff\n",
    "- Additional edge feature: same_chain_flag (0 or 1)\n",
    "- Output: `protein_complex.pt`\n",
    "\n",
    "### Usage Instructions\n",
    "\n",
    "1. **Edit the User Configuration cell** below with your paths and parameters\n",
    "2. **Run all cells** sequentially (Cell → Run All)\n",
    "3. **Check outputs** in the specified OUTPUT_DIR\n",
    "\n",
    "### Output Files\n",
    "\n",
    "```\n",
    "OUTPUT_DIR/\n",
    "├── graphs_monomer/              # Per-chain graphs\n",
    "├── graphs_complex/              # Multi-chain complex graphs\n",
    "├── dataset_summary_monomer.csv\n",
    "├── dataset_summary_complex.csv\n",
    "├── failed_structures.txt\n",
    "└── graph_definition.json\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if not already installed)\n",
    "# Uncomment the following line if running in Google Colab or a fresh environment\n",
    "# !pip install biopython torch torch-geometric numpy pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from Bio import BiopythonWarning\n",
    "from Bio.PDB import PDBParser, PPBuilder\n",
    "from Bio.PDB.Structure import Structure\n",
    "from Bio.PDB.Chain import Chain\n",
    "from Bio.PDB.Residue import Residue\n",
    "\n",
    "# Suppress Biopython warnings for cleaner output\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  NumPy version: {np.__version__}\")\n",
    "print(f\"  Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Version & Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(f\"✓ Random seed set to {RANDOM_SEED}\")\n",
    "print(f\"  Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User Configuration\n",
    "\n",
    "**⚠️ EDIT THIS CELL WITH YOUR PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# USER CONFIGURATION - EDIT THIS CELL ONLY\n",
    "# ============================================================\n",
    "\n",
    "# Input/Output Directories\n",
    "INPUT_DIR = \"data/pdb_files/\"           # Folder containing PDB files\n",
    "OUTPUT_DIR = \"data/graphs/\"             # Output directory for graphs\n",
    "\n",
    "# Graph Construction Parameters\n",
    "DISTANCE_CUTOFF_ANGSTROM = 8.0          # Cα-Cα distance cutoff (Å)\n",
    "\n",
    "# Structure Filtering Options\n",
    "REMOVE_WATER = True                      # Remove water residues\n",
    "REMOVE_HETERO = True                     # Remove heteroatoms (ligands, ions)\n",
    "MIN_RESIDUES = 10                        # Minimum residues per chain\n",
    "\n",
    "# Output Format\n",
    "SAVE_FORMAT = \"pyg\"                      # 'pyg' for PyTorch Geometric\n",
    "\n",
    "# ============================================================\n",
    "# END OF USER CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Validate configuration\n",
    "assert Path(INPUT_DIR).exists(), f\"INPUT_DIR does not exist: {INPUT_DIR}\"\n",
    "assert DISTANCE_CUTOFF_ANGSTROM > 0, \"DISTANCE_CUTOFF_ANGSTROM must be positive\"\n",
    "assert MIN_RESIDUES > 0, \"MIN_RESIDUES must be positive\"\n",
    "assert SAVE_FORMAT in [\"pyg\"], f\"SAVE_FORMAT must be 'pyg', got {SAVE_FORMAT}\"\n",
    "\n",
    "# Create output directories\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_DIR, \"graphs_monomer\").mkdir(exist_ok=True)\n",
    "Path(OUTPUT_DIR, \"graphs_complex\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✓ Configuration validated\")\n",
    "print(f\"  Input directory: {INPUT_DIR}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Distance cutoff: {DISTANCE_CUTOFF_ANGSTROM} Å\")\n",
    "print(f\"  Min residues: {MIN_RESIDUES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Amino Acid Encoding Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard 20 amino acids (3-letter to 1-letter code)\n",
    "AA_3_TO_1 = {\n",
    "    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E',\n",
    "    'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
    "    'LYS': 'K', 'LEU': 'L', 'MET': 'M', 'ASN': 'N',\n",
    "    'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S',\n",
    "    'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'\n",
    "}\n",
    "\n",
    "# Mapping amino acids to indices for one-hot encoding\n",
    "AA_TO_INDEX = {aa: idx for idx, aa in enumerate(sorted(AA_3_TO_1.keys()))}\n",
    "INDEX_TO_AA = {idx: aa for aa, idx in AA_TO_INDEX.items()}\n",
    "\n",
    "NUM_AA_TYPES = len(AA_TO_INDEX)\n",
    "\n",
    "print(f\"✓ Amino acid encoding tables created\")\n",
    "print(f\"  Number of standard amino acids: {NUM_AA_TYPES}\")\n",
    "print(f\"  Example: {list(AA_TO_INDEX.items())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PDB Parsing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ResidueData:\n",
    "    \"\"\"Container for residue information.\"\"\"\n",
    "    residue_name: str\n",
    "    residue_index: int\n",
    "    chain_id: str\n",
    "    ca_coords: np.ndarray\n",
    "    \n",
    "\n",
    "def is_valid_residue(residue: Residue, remove_water: bool, remove_hetero: bool) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a residue should be included in the graph.\n",
    "    \n",
    "    Args:\n",
    "        residue: BioPython Residue object\n",
    "        remove_water: Whether to exclude water molecules\n",
    "        remove_hetero: Whether to exclude heteroatoms\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if residue is valid for inclusion\n",
    "    \"\"\"\n",
    "    hetfield = residue.get_id()[0]\n",
    "    \n",
    "    # Check if water\n",
    "    if remove_water and hetfield == 'W':\n",
    "        return False\n",
    "    \n",
    "    # Check if heteroatom (ligands, ions, modified residues)\n",
    "    if remove_hetero and hetfield.startswith('H'):\n",
    "        return False\n",
    "    \n",
    "    # Must be a standard amino acid\n",
    "    if residue.get_resname() not in AA_TO_INDEX:\n",
    "        return False\n",
    "    \n",
    "    # Must have Cα atom\n",
    "    if 'CA' not in residue:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def parse_pdb_structure(pdb_path: str, remove_water: bool, remove_hetero: bool) -> Optional[Structure]:\n",
    "    \"\"\"\n",
    "    Parse a PDB file and return the structure.\n",
    "    \n",
    "    Args:\n",
    "        pdb_path: Path to PDB file\n",
    "        remove_water: Whether to exclude water molecules\n",
    "        remove_hetero: Whether to exclude heteroatoms\n",
    "        \n",
    "    Returns:\n",
    "        Structure object or None if parsing fails\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    \n",
    "    try:\n",
    "        structure_id = Path(pdb_path).stem\n",
    "        structure = parser.get_structure(structure_id, pdb_path)\n",
    "        return structure\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed to parse {pdb_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_residue_data(\n",
    "    chain: Chain,\n",
    "    remove_water: bool,\n",
    "    remove_hetero: bool\n",
    ") -> List[ResidueData]:\n",
    "    \"\"\"\n",
    "    Extract residue data from a protein chain.\n",
    "    \n",
    "    Args:\n",
    "        chain: BioPython Chain object\n",
    "        remove_water: Whether to exclude water molecules\n",
    "        remove_hetero: Whether to exclude heteroatoms\n",
    "        \n",
    "    Returns:\n",
    "        List of ResidueData objects\n",
    "    \"\"\"\n",
    "    residue_list = []\n",
    "    \n",
    "    for residue in chain:\n",
    "        if not is_valid_residue(residue, remove_water, remove_hetero):\n",
    "            continue\n",
    "        \n",
    "        # Extract Cα coordinates\n",
    "        ca_atom = residue['CA']\n",
    "        ca_coords = ca_atom.get_coord()\n",
    "        \n",
    "        # Store residue data\n",
    "        residue_data = ResidueData(\n",
    "            residue_name=residue.get_resname(),\n",
    "            residue_index=residue.get_id()[1],  # Residue sequence number\n",
    "            chain_id=chain.get_id(),\n",
    "            ca_coords=ca_coords\n",
    "        )\n",
    "        residue_list.append(residue_data)\n",
    "    \n",
    "    return residue_list\n",
    "\n",
    "\n",
    "print(\"✓ PDB parsing utilities defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Residue Feature Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_node_features(\n",
    "    residues: List[ResidueData],\n",
    "    chain_to_idx: Optional[Dict[str, int]] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build node feature matrix from residue data.\n",
    "    \n",
    "    Features per node:\n",
    "    - [0:20]: Amino acid one-hot encoding\n",
    "    - [20]: Residue index\n",
    "    - [21]: Chain ID (encoded)\n",
    "    - [22:25]: Cα xyz coordinates\n",
    "    \n",
    "    Args:\n",
    "        residues: List of ResidueData objects\n",
    "        chain_to_idx: Optional mapping from chain_id to integer index\n",
    "        \n",
    "    Returns:\n",
    "        Node feature matrix of shape (num_residues, 25)\n",
    "    \"\"\"\n",
    "    num_residues = len(residues)\n",
    "    node_features = np.zeros((num_residues, NUM_AA_TYPES + 5), dtype=np.float32)\n",
    "    \n",
    "    # Create chain encoding if not provided\n",
    "    if chain_to_idx is None:\n",
    "        unique_chains = sorted(set(r.chain_id for r in residues))\n",
    "        chain_to_idx = {chain: idx for idx, chain in enumerate(unique_chains)}\n",
    "    \n",
    "    for i, res in enumerate(residues):\n",
    "        # One-hot encode amino acid\n",
    "        aa_idx = AA_TO_INDEX[res.residue_name]\n",
    "        node_features[i, aa_idx] = 1.0\n",
    "        \n",
    "        # Residue index\n",
    "        node_features[i, NUM_AA_TYPES] = res.residue_index\n",
    "        \n",
    "        # Chain ID (encoded)\n",
    "        node_features[i, NUM_AA_TYPES + 1] = chain_to_idx[res.chain_id]\n",
    "        \n",
    "        # Cα coordinates\n",
    "        node_features[i, NUM_AA_TYPES + 2:NUM_AA_TYPES + 5] = res.ca_coords\n",
    "    \n",
    "    return node_features\n",
    "\n",
    "\n",
    "print(\"✓ Node feature builder defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Distance Computation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(ca_coords: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute pairwise Euclidean distance matrix between Cα atoms.\n",
    "    \n",
    "    Args:\n",
    "        ca_coords: Cα coordinates array of shape (num_residues, 3)\n",
    "        \n",
    "    Returns:\n",
    "        Distance matrix of shape (num_residues, num_residues)\n",
    "    \"\"\"\n",
    "    # Efficient vectorized distance computation\n",
    "    diff = ca_coords[:, np.newaxis, :] - ca_coords[np.newaxis, :, :]\n",
    "    distances = np.sqrt(np.sum(diff ** 2, axis=2))\n",
    "    return distances\n",
    "\n",
    "\n",
    "print(\"✓ Distance computation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cutoff Edge Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edges_from_cutoff(\n",
    "    distance_matrix: np.ndarray,\n",
    "    cutoff: float,\n",
    "    self_loops: bool = False\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build edge index and edge attributes based on distance cutoff.\n",
    "    \n",
    "    Creates undirected edges (both directions) for residue pairs within cutoff.\n",
    "    \n",
    "    Args:\n",
    "        distance_matrix: Pairwise distance matrix\n",
    "        cutoff: Maximum distance for edge creation (Angstroms)\n",
    "        self_loops: Whether to include self-loops (default: False)\n",
    "        \n",
    "    Returns:\n",
    "        edge_index: Edge connectivity (2, num_edges)\n",
    "        edge_attr: Edge features (num_edges, 1) containing distances\n",
    "    \"\"\"\n",
    "    num_nodes = distance_matrix.shape[0]\n",
    "    \n",
    "    # Find edges within cutoff\n",
    "    if self_loops:\n",
    "        mask = distance_matrix <= cutoff\n",
    "    else:\n",
    "        mask = (distance_matrix <= cutoff) & (distance_matrix > 0)\n",
    "    \n",
    "    # Get edge indices\n",
    "    src, dst = np.where(mask)\n",
    "    \n",
    "    # Edge features (distances)\n",
    "    edge_distances = distance_matrix[src, dst]\n",
    "    \n",
    "    # Create edge index (PyTorch Geometric format)\n",
    "    edge_index = np.stack([src, dst], axis=0)\n",
    "    edge_attr = edge_distances.reshape(-1, 1)\n",
    "    \n",
    "    return edge_index, edge_attr\n",
    "\n",
    "\n",
    "def build_edges_with_chain_info(\n",
    "    distance_matrix: np.ndarray,\n",
    "    chain_ids: np.ndarray,\n",
    "    cutoff: float,\n",
    "    self_loops: bool = False\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build edges with additional chain information for multi-chain graphs.\n",
    "    \n",
    "    Args:\n",
    "        distance_matrix: Pairwise distance matrix\n",
    "        chain_ids: Array of chain IDs for each node\n",
    "        cutoff: Maximum distance for edge creation\n",
    "        self_loops: Whether to include self-loops\n",
    "        \n",
    "    Returns:\n",
    "        edge_index: Edge connectivity (2, num_edges)\n",
    "        edge_attr: Edge features (num_edges, 2) [distance, same_chain_flag]\n",
    "    \"\"\"\n",
    "    # Build basic edges\n",
    "    edge_index, edge_distances = build_edges_from_cutoff(\n",
    "        distance_matrix, cutoff, self_loops\n",
    "    )\n",
    "    \n",
    "    # Determine if edges are intra-chain or inter-chain\n",
    "    src_chains = chain_ids[edge_index[0]]\n",
    "    dst_chains = chain_ids[edge_index[1]]\n",
    "    same_chain = (src_chains == dst_chains).astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Combine edge features\n",
    "    edge_attr = np.hstack([edge_distances, same_chain])\n",
    "    \n",
    "    return edge_index, edge_attr\n",
    "\n",
    "\n",
    "print(\"✓ Edge builder functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Graph Builder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_protein_graph(\n",
    "    residues: List[ResidueData],\n",
    "    cutoff: float,\n",
    "    include_chain_info: bool = False,\n",
    "    chain_to_idx: Optional[Dict[str, int]] = None\n",
    ") -> Data:\n",
    "    \"\"\"\n",
    "    Build a PyTorch Geometric graph from residue data.\n",
    "    \n",
    "    Args:\n",
    "        residues: List of ResidueData objects\n",
    "        cutoff: Distance cutoff for edge creation (Angstroms)\n",
    "        include_chain_info: Whether to include chain info in edge features\n",
    "        chain_to_idx: Optional chain ID to index mapping\n",
    "        \n",
    "    Returns:\n",
    "        PyTorch Geometric Data object\n",
    "    \"\"\"\n",
    "    # Build node features\n",
    "    node_features = build_node_features(residues, chain_to_idx)\n",
    "    \n",
    "    # Extract Cα coordinates for distance computation\n",
    "    ca_coords = np.array([r.ca_coords for r in residues])\n",
    "    \n",
    "    # Compute distance matrix\n",
    "    distance_matrix = compute_distance_matrix(ca_coords)\n",
    "    \n",
    "    # Build edges\n",
    "    if include_chain_info:\n",
    "        chain_ids = node_features[:, NUM_AA_TYPES + 1]  # Extract chain IDs\n",
    "        edge_index, edge_attr = build_edges_with_chain_info(\n",
    "            distance_matrix, chain_ids, cutoff, self_loops=False\n",
    "        )\n",
    "    else:\n",
    "        edge_index, edge_attr = build_edges_from_cutoff(\n",
    "            distance_matrix, cutoff, self_loops=False\n",
    "        )\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    x = torch.from_numpy(node_features).float()\n",
    "    edge_index = torch.from_numpy(edge_index).long()\n",
    "    edge_attr = torch.from_numpy(edge_attr).float()\n",
    "    \n",
    "    # Create PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        num_nodes=len(residues)\n",
    "    )\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "print(\"✓ Graph builder function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Monomer Graph Pipeline\n",
    "\n",
    "### Generate Single-Chain Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_monomer_graphs(\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    cutoff: float,\n",
    "    remove_water: bool,\n",
    "    remove_hetero: bool,\n",
    "    min_residues: int\n",
    ") -> Tuple[List[Dict], List[str]]:\n",
    "    \"\"\"\n",
    "    Process all PDB files and generate monomer (single-chain) graphs.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing PDB files\n",
    "        output_dir: Directory to save graphs\n",
    "        cutoff: Distance cutoff (Angstroms)\n",
    "        remove_water: Whether to exclude water\n",
    "        remove_hetero: Whether to exclude heteroatoms\n",
    "        min_residues: Minimum residues per chain\n",
    "        \n",
    "    Returns:\n",
    "        summary_data: List of dictionaries with graph statistics\n",
    "        failed_structures: List of failed structure IDs with reasons\n",
    "    \"\"\"\n",
    "    pdb_files = list(Path(input_dir).glob(\"*.pdb\"))\n",
    "    \n",
    "    if len(pdb_files) == 0:\n",
    "        print(f\"⚠ No PDB files found in {input_dir}\")\n",
    "        return [], []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MONOMER GRAPH GENERATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Found {len(pdb_files)} PDB files\\n\")\n",
    "    \n",
    "    summary_data = []\n",
    "    failed_structures = []\n",
    "    \n",
    "    output_subdir = Path(output_dir) / \"graphs_monomer\"\n",
    "    output_subdir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for pdb_file in tqdm(pdb_files, desc=\"Processing structures\"):\n",
    "        protein_id = pdb_file.stem\n",
    "        \n",
    "        # Parse structure\n",
    "        structure = parse_pdb_structure(str(pdb_file), remove_water, remove_hetero)\n",
    "        if structure is None:\n",
    "            failed_structures.append(f\"{protein_id}: Failed to parse PDB\")\n",
    "            continue\n",
    "        \n",
    "        # Process each chain independently\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                chain_id = chain.get_id()\n",
    "                \n",
    "                # Extract residues\n",
    "                residues = extract_residue_data(chain, remove_water, remove_hetero)\n",
    "                \n",
    "                # Skip chains that are too short\n",
    "                if len(residues) < min_residues:\n",
    "                    failed_structures.append(\n",
    "                        f\"{protein_id}_chain{chain_id}: Only {len(residues)} residues (< {min_residues})\"\n",
    "                    )\n",
    "                    continue\n",
    "                \n",
    "                # Build graph\n",
    "                try:\n",
    "                    graph = build_protein_graph(\n",
    "                        residues,\n",
    "                        cutoff=cutoff,\n",
    "                        include_chain_info=False\n",
    "                    )\n",
    "                    \n",
    "                    # Save graph\n",
    "                    output_path = output_subdir / f\"{protein_id}_{chain_id}.pt\"\n",
    "                    torch.save(graph, output_path)\n",
    "                    \n",
    "                    # Record statistics\n",
    "                    summary_data.append({\n",
    "                        'protein_id': protein_id,\n",
    "                        'chain_id': chain_id,\n",
    "                        'num_nodes': graph.num_nodes,\n",
    "                        'num_edges': graph.num_edges,\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    failed_structures.append(\n",
    "                        f\"{protein_id}_chain{chain_id}: Graph build failed - {str(e)}\"\n",
    "                    )\n",
    "    \n",
    "    print(f\"\\n✓ Monomer graphs generated: {len(summary_data)}\")\n",
    "    print(f\"✗ Failed structures: {len(failed_structures)}\")\n",
    "    \n",
    "    return summary_data, failed_structures\n",
    "\n",
    "\n",
    "print(\"✓ Monomer graph pipeline defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Monomer Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate monomer graphs\n",
    "monomer_summary, monomer_failed = process_monomer_graphs(\n",
    "    input_dir=INPUT_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    cutoff=DISTANCE_CUTOFF_ANGSTROM,\n",
    "    remove_water=REMOVE_WATER,\n",
    "    remove_hetero=REMOVE_HETERO,\n",
    "    min_residues=MIN_RESIDUES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Complex (Multi-Chain) Graph Pipeline\n",
    "\n",
    "### Generate Multi-Chain Complex Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_complex_graphs(\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    cutoff: float,\n",
    "    remove_water: bool,\n",
    "    remove_hetero: bool,\n",
    "    min_residues: int\n",
    ") -> Tuple[List[Dict], List[str]]:\n",
    "    \"\"\"\n",
    "    Process all PDB files and generate complex (multi-chain) graphs.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing PDB files\n",
    "        output_dir: Directory to save graphs\n",
    "        cutoff: Distance cutoff (Angstroms)\n",
    "        remove_water: Whether to exclude water\n",
    "        remove_hetero: Whether to exclude heteroatoms\n",
    "        min_residues: Minimum total residues in structure\n",
    "        \n",
    "    Returns:\n",
    "        summary_data: List of dictionaries with graph statistics\n",
    "        failed_structures: List of failed structure IDs with reasons\n",
    "    \"\"\"\n",
    "    pdb_files = list(Path(input_dir).glob(\"*.pdb\"))\n",
    "    \n",
    "    if len(pdb_files) == 0:\n",
    "        print(f\"⚠ No PDB files found in {input_dir}\")\n",
    "        return [], []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"COMPLEX (MULTI-CHAIN) GRAPH GENERATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Found {len(pdb_files)} PDB files\\n\")\n",
    "    \n",
    "    summary_data = []\n",
    "    failed_structures = []\n",
    "    \n",
    "    output_subdir = Path(output_dir) / \"graphs_complex\"\n",
    "    output_subdir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for pdb_file in tqdm(pdb_files, desc=\"Processing structures\"):\n",
    "        protein_id = pdb_file.stem\n",
    "        \n",
    "        # Parse structure\n",
    "        structure = parse_pdb_structure(str(pdb_file), remove_water, remove_hetero)\n",
    "        if structure is None:\n",
    "            failed_structures.append(f\"{protein_id}: Failed to parse PDB\")\n",
    "            continue\n",
    "        \n",
    "        # Combine all chains in the structure\n",
    "        all_residues = []\n",
    "        chain_ids = []\n",
    "        \n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                chain_id = chain.get_id()\n",
    "                residues = extract_residue_data(chain, remove_water, remove_hetero)\n",
    "                \n",
    "                if len(residues) > 0:\n",
    "                    all_residues.extend(residues)\n",
    "                    chain_ids.append(chain_id)\n",
    "        \n",
    "        # Skip if structure has too few residues\n",
    "        if len(all_residues) < min_residues:\n",
    "            failed_structures.append(\n",
    "                f\"{protein_id}: Only {len(all_residues)} total residues (< {min_residues})\"\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        # Build complex graph\n",
    "        try:\n",
    "            # Create chain ID to index mapping\n",
    "            unique_chains = sorted(set(chain_ids))\n",
    "            chain_to_idx = {chain: idx for idx, chain in enumerate(unique_chains)}\n",
    "            \n",
    "            graph = build_protein_graph(\n",
    "                all_residues,\n",
    "                cutoff=cutoff,\n",
    "                include_chain_info=True,\n",
    "                chain_to_idx=chain_to_idx\n",
    "            )\n",
    "            \n",
    "            # Save graph\n",
    "            output_path = output_subdir / f\"{protein_id}_complex.pt\"\n",
    "            torch.save(graph, output_path)\n",
    "            \n",
    "            # Count inter-chain edges\n",
    "            same_chain_flags = graph.edge_attr[:, 1]\n",
    "            num_inter_chain = int((same_chain_flags == 0).sum().item())\n",
    "            \n",
    "            # Record statistics\n",
    "            summary_data.append({\n",
    "                'protein_id': protein_id,\n",
    "                'num_chains': len(unique_chains),\n",
    "                'num_nodes': graph.num_nodes,\n",
    "                'num_edges': graph.num_edges,\n",
    "                'num_inter_chain_edges': num_inter_chain,\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_structures.append(\n",
    "                f\"{protein_id}: Graph build failed - {str(e)}\"\n",
    "            )\n",
    "    \n",
    "    print(f\"\\n✓ Complex graphs generated: {len(summary_data)}\")\n",
    "    print(f\"✗ Failed structures: {len(failed_structures)}\")\n",
    "    \n",
    "    return summary_data, failed_structures\n",
    "\n",
    "\n",
    "print(\"✓ Complex graph pipeline defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Complex Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complex graphs\n",
    "complex_summary, complex_failed = process_complex_graphs(\n",
    "    input_dir=INPUT_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    cutoff=DISTANCE_CUTOFF_ANGSTROM,\n",
    "    remove_water=REMOVE_WATER,\n",
    "    remove_hetero=REMOVE_HETERO,\n",
    "    min_residues=MIN_RESIDUES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Summary Data & Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save monomer summary\n",
    "if len(monomer_summary) > 0:\n",
    "    df_monomer = pd.DataFrame(monomer_summary)\n",
    "    monomer_csv_path = Path(OUTPUT_DIR) / \"dataset_summary_monomer.csv\"\n",
    "    df_monomer.to_csv(monomer_csv_path, index=False)\n",
    "    print(f\"✓ Saved monomer summary: {monomer_csv_path}\")\n",
    "    \n",
    "    # Display statistics\n",
    "    print(\"\\nMonomer Graph Statistics:\")\n",
    "    print(df_monomer.describe())\n",
    "else:\n",
    "    print(\"⚠ No monomer graphs generated\")\n",
    "\n",
    "# Save complex summary\n",
    "if len(complex_summary) > 0:\n",
    "    df_complex = pd.DataFrame(complex_summary)\n",
    "    complex_csv_path = Path(OUTPUT_DIR) / \"dataset_summary_complex.csv\"\n",
    "    df_complex.to_csv(complex_csv_path, index=False)\n",
    "    print(f\"\\n✓ Saved complex summary: {complex_csv_path}\")\n",
    "    \n",
    "    # Display statistics\n",
    "    print(\"\\nComplex Graph Statistics:\")\n",
    "    print(df_complex.describe())\n",
    "else:\n",
    "    print(\"⚠ No complex graphs generated\")\n",
    "\n",
    "# Save failed structures log\n",
    "all_failed = monomer_failed + complex_failed\n",
    "if len(all_failed) > 0:\n",
    "    failed_path = Path(OUTPUT_DIR) / \"failed_structures.txt\"\n",
    "    with open(failed_path, 'w') as f:\n",
    "        f.write(\"Failed Structures and Reasons\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        for item in all_failed:\n",
    "            f.write(f\"{item}\\n\")\n",
    "    print(f\"\\n✓ Saved failed structures log: {failed_path}\")\n",
    "else:\n",
    "    print(\"\\n✓ All structures processed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Graph Definition (Scientific Transparency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph definition metadata\n",
    "graph_definition = {\n",
    "    \"version\": \"1.0\",\n",
    "    \"created_date\": pd.Timestamp.now().isoformat(),\n",
    "    \"graph_specification\": {\n",
    "        \"node_definition\": \"One node per residue with Cα atom present\",\n",
    "        \"edge_rule\": f\"Undirected edges when Cα-Cα distance ≤ {DISTANCE_CUTOFF_ANGSTROM} Å\",\n",
    "        \"distance_cutoff_angstrom\": DISTANCE_CUTOFF_ANGSTROM,\n",
    "        \"node_features\": {\n",
    "            \"amino_acid_onehot\": \"20 standard amino acids (indices 0-19)\",\n",
    "            \"residue_index\": \"Sequential residue number (index 20)\",\n",
    "            \"chain_id\": \"Encoded chain identifier (index 21)\",\n",
    "            \"ca_coordinates\": \"xyz coordinates in Angstroms (indices 22-24)\"\n",
    "        },\n",
    "        \"edge_features\": {\n",
    "            \"distance\": \"Euclidean distance between Cα atoms (Angstroms)\",\n",
    "            \"same_chain_flag\": \"Binary flag (complex mode only): 1=same chain, 0=different chains\"\n",
    "        }\n",
    "    },\n",
    "    \"processing_parameters\": {\n",
    "        \"remove_water\": REMOVE_WATER,\n",
    "        \"remove_hetero\": REMOVE_HETERO,\n",
    "        \"min_residues\": MIN_RESIDUES\n",
    "    },\n",
    "    \"amino_acid_encoding\": AA_TO_INDEX,\n",
    "    \"statistics\": {\n",
    "        \"total_monomer_graphs\": len(monomer_summary),\n",
    "        \"total_complex_graphs\": len(complex_summary),\n",
    "        \"failed_structures\": len(all_failed)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save graph definition\n",
    "definition_path = Path(OUTPUT_DIR) / \"graph_definition.json\"\n",
    "with open(definition_path, 'w') as f:\n",
    "    json.dump(graph_definition, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved graph definition: {definition_path}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRAPH SPECIFICATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Node definition: One node per residue with Cα atom\")\n",
    "print(f\"Distance cutoff: {DISTANCE_CUTOFF_ANGSTROM} Å\")\n",
    "print(f\"Edge rule: Undirected edges when Cα-Cα distance ≤ cutoff\")\n",
    "print(f\"\\nNode features ({NUM_AA_TYPES + 5} total):\")\n",
    "print(f\"  - Amino acid one-hot (20)\")\n",
    "print(f\"  - Residue index (1)\")\n",
    "print(f\"  - Chain ID encoded (1)\")\n",
    "print(f\"  - Cα coordinates xyz (3)\")\n",
    "print(f\"\\nEdge features:\")\n",
    "print(f\"  - Monomer mode: Distance (1)\")\n",
    "print(f\"  - Complex mode: Distance + same_chain_flag (2)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Example: Load and Inspect a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load a generated graph and inspect its properties\n",
    "print(\"\\nExample: Loading and inspecting a graph\\n\")\n",
    "\n",
    "# Try to load a monomer graph\n",
    "monomer_graphs = list(Path(OUTPUT_DIR, \"graphs_monomer\").glob(\"*.pt\"))\n",
    "if len(monomer_graphs) > 0:\n",
    "    example_graph_path = monomer_graphs[0]\n",
    "    graph = torch.load(example_graph_path)\n",
    "    \n",
    "    print(f\"Loaded graph: {example_graph_path.name}\")\n",
    "    print(f\"  Number of nodes (residues): {graph.num_nodes}\")\n",
    "    print(f\"  Number of edges: {graph.num_edges}\")\n",
    "    print(f\"  Node feature shape: {graph.x.shape}\")\n",
    "    print(f\"  Edge index shape: {graph.edge_index.shape}\")\n",
    "    print(f\"  Edge attribute shape: {graph.edge_attr.shape}\")\n",
    "    \n",
    "    # Show feature breakdown\n",
    "    print(f\"\\n  Node features breakdown:\")\n",
    "    print(f\"    - Amino acid one-hot: [:, 0:20]\")\n",
    "    print(f\"    - Residue index: [:, 20]\")\n",
    "    print(f\"    - Chain ID: [:, 21]\")\n",
    "    print(f\"    - Cα coordinates: [:, 22:25]\")\n",
    "    \n",
    "    # Show edge statistics\n",
    "    edge_distances = graph.edge_attr[:, 0]\n",
    "    print(f\"\\n  Edge distance statistics (Å):\")\n",
    "    print(f\"    - Min: {edge_distances.min():.2f}\")\n",
    "    print(f\"    - Max: {edge_distances.max():.2f}\")\n",
    "    print(f\"    - Mean: {edge_distances.mean():.2f}\")\n",
    "    print(f\"    - Median: {edge_distances.median():.2f}\")\n",
    "else:\n",
    "    print(\"No graphs generated to display example.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"All outputs saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After running this notebook, you can:\n",
    "\n",
    "1. **Load graphs for machine learning:**\n",
    "   ```python\n",
    "   import torch\n",
    "   graph = torch.load('data/graphs/graphs_monomer/protein_A.pt')\n",
    "   ```\n",
    "\n",
    "2. **Create PyTorch Geometric datasets:**\n",
    "   ```python\n",
    "   from torch_geometric.data import Dataset, DataLoader\n",
    "   # Build your custom dataset class\n",
    "   ```\n",
    "\n",
    "3. **Train graph neural networks:**\n",
    "   - Use the generated graphs as input to GNN models\n",
    "   - Tasks: protein function prediction, interaction prediction, etc.\n",
    "\n",
    "4. **Analyze graph properties:**\n",
    "   - Load the CSV summaries for statistical analysis\n",
    "   - Visualize graph size distributions\n",
    "   - Study inter-chain connectivity patterns\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
